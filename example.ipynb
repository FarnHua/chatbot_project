{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarnHua/chatbot_project/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bhm7pWHiLqJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd drive/MyDrive\n",
        "# # !mkdir Chatbot-Project\n",
        "# %cd Chatbot-Project/Chatbot-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJqdb2m2Lw_n",
        "outputId": "0522d0da-08d3-44a3-9b76-e18756289c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/Chatbot-Project/Chatbot-Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rod2G6ROQtsk"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/FarnHua/chatbot_project.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd chatbot_project"
      ],
      "metadata": {
        "id": "EWfr9DdrwVJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!wget https://drive.google.com/u/1/uc?id=1FZu2HIadORIvGD5nJAIOG6NjgtXrNXrz&export=download\n",
        "!gdown https://drive.google.com/u/1/uc?id=1FZu2HIadORIvGD5nJAIOG6NjgtXrNXrz&export=download\n",
        "!unzip Emo_detector.zip\n",
        "!rm Emo_detector.zip"
      ],
      "metadata": {
        "id": "innQOS7mRMfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install boto3\n",
        "!pip install pytorch-pretrained-bert"
      ],
      "metadata": {
        "id": "9IZPzvW6SgWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "vp8lbMSdxMoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "sWZuXno05j3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_c.py --inter gpt --model gpt2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGiWmaeVWXQg",
        "outputId": "eb899e1f-5e61-4f62-a2b0-50ad647c8481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
            "09/20/2022 17:15:45 - INFO - pytorch_pretrained_bert.modeling -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfarnhua\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "cached_path, parsed:  ParseResult(scheme='', netloc='', path='./Emo_detector/emotion_unit/models/bert-large-uncased-vocab.txt', params='', query='', fragment='') ~~~\n",
            "resolved_vocab_file:  ./Emo_detector/emotion_unit/models/bert-large-uncased-vocab.txt ~~~~~~\n",
            "09/20/2022 17:15:47 - INFO - Emo_detector.emotion_unit.pytorch_pretrained_bert.tokenization -   loading vocabulary file ./Emo_detector/emotion_unit/models/bert-large-uncased-vocab.txt\n",
            "########Here is the function of BertTokenizer########\n",
            "BertForSequenceRegressionClassification_map, config:  {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            " ~~~\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/chatbot_project/wandb/run-20220920_171552-i4nqb7xc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmodel/save/\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/farnhua/chatbot_softprompt\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/farnhua/chatbot_softprompt/runs/i4nqb7xc\u001b[0m\n",
            "  0% 3/5785 [00:10<5:19:29,  3.32s/it]/content/chatbot_project/lsp_model/optim.py:187: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "  3% 154/5785 [08:05<4:40:39,  2.99s/it]"
          ]
        }
      ]
    }
  ]
}